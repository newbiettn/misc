{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09290135-4df6-4e0d-9a10-3b65385de8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d33f8e14-ccb7-4a79-8a03-65c857742b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "HUBS = Path(\"/Users/ngoc.tran/lexer/ops-data/workflows/hubs\")\n",
    "CSV_DIR = \"csv\"\n",
    "SCHEDULES_COLLECTION_FILE = \"ALL_CLIENTS_schedules.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9f783c7-9825-48f3-a953-1b046e6da3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_schedule(schedule_path: Path):\n",
    "    with schedule_path.open(\"r\") as f:\n",
    "        return json.loads(f.read())\n",
    "\n",
    "def save_schedule(scheule_path: Path, schedule: dict):\n",
    "    with scheule_path.open(\"w\") as f:\n",
    "        return f.write(json.dumps(schedule, indent=4) + \"\\n\")\n",
    "\n",
    "def write_dicts_to_csv(data, directory, file_name):\n",
    "    if not data:\n",
    "        raise ValueError(\"Schedule should not be empty\")\n",
    "\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "\n",
    "    csv_file = os.path.join(directory, file_name)\n",
    "\n",
    "    # Open the file in write mode\n",
    "    with open(csv_file, mode='w', newline='') as file:\n",
    "        # Create a csv.DictWriter object\n",
    "        writer = csv.DictWriter(file, fieldnames=data[0].keys())\n",
    "        \n",
    "        # Write the header\n",
    "        writer.writeheader()\n",
    "        \n",
    "        # Write the rows\n",
    "        writer.writerows(data)\n",
    "\n",
    "    print(f'Data successfully written to {csv_file}')\n",
    "\n",
    "def parse_cron_expression(cron_expr):\n",
    "    # Split the cron expression into parts\n",
    "    parts = cron_expr.split()\n",
    "    \n",
    "    # Define the labels for each part of the cron expression\n",
    "    labels = [\"seconds\", \n",
    "              \"minutes\", \n",
    "              \"hours\", \n",
    "              \"day_of_the_month\", \n",
    "              \"month\", \n",
    "              \"day_of_the_week\", \n",
    "              \"cron_optional\"]\n",
    "    \n",
    "    # Check if the expression includes the optional Year part\n",
    "    if len(parts) == 6:\n",
    "        parts.append(\"\")\n",
    "    \n",
    "    # Create a dictionary to hold the parsed parts\n",
    "    cron_parts = {}\n",
    "    \n",
    "    # Populate the dictionary with the parts\n",
    "    for label, part in zip(labels, parts):\n",
    "        cron_parts[label] = part\n",
    "    \n",
    "    return cron_parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee73083-7cba-49af-a342-e4720a5c4fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "schedule_list = []\n",
    "for hub in HUBS.iterdir():\n",
    "    if hub.is_dir():\n",
    "        schedules = hub / \"schedules\"\n",
    "        if schedules.is_dir():\n",
    "            for p in schedules.iterdir():\n",
    "                record = {}\n",
    "                record[\"client\"] = str(p).split(\"/\")[-3]\n",
    "                try:\n",
    "                    s = read_schedule(p)\n",
    "                    if s[\"schedule\"][\"pause_status\"] == \"UNPAUSED\":\n",
    "                        jt = s[\"job_type\"]\n",
    "                        record[\"job_type\"] = jt\n",
    "                        cron = parse_cron_expression(s[\"schedule\"][\"quartz_cron_expression\"])\n",
    "                        record[\"seconds\"] = cron[\"seconds\"]\n",
    "                        record[\"minutes\"] = cron[\"minutes\"]\n",
    "                        record[\"hours\"] = cron[\"hours\"]\n",
    "                        record[\"day_of_the_month\"] = cron[\"day_of_the_month\"]\n",
    "                        record[\"month\"] = cron[\"month\"]\n",
    "                        record[\"day_of_the_week\"] = cron[\"day_of_the_week\"]\n",
    "                        record[\"cron_optional\"] = cron[\"cron_optional\"]\n",
    "                        record[\"cron\"] = s[\"schedule\"][\"quartz_cron_expression\"]\n",
    "                        record[\"region\"] = s[\"region\"]\n",
    "                        if ((jt == \"load_dataset\") or (jt == \"run_enrichment\")):\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"service_name\"]\n",
    "                        elif jt == \"run_dataflow\":\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"dataflow_config\"][\"name\"]\n",
    "                        elif jt == \"build_index\":\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"build_config\"][\"namespace\"]\n",
    "                            service_name = service_name.split(\".\")[2] + \"_index\"\n",
    "                        elif jt == \"build_features\":\n",
    "                            filename = str(p).split(\"/\")[-1]\n",
    "                            filename = filename.split(\".\")[0]\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"client\"] + \"_\" + filename\n",
    "                        elif jt == \"unification_job\":\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"bucket\"]\n",
    "                            service_name = service_name.split(\"-\")[2] + \"_unification\"\n",
    "                        elif jt == \"run_report\":\n",
    "                            service_name = s[\"notebook_task\"][\"base_parameters\"][\"bucket\"]\n",
    "                            service_name = service_name.split(\"-\")[2] + \"_report\"\n",
    "                        record[\"service_name\"] = service_name\n",
    "                        record[\"fname\"] = str(p)\n",
    "                        schedule_list.append(record)\n",
    "                except Exception as e:\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7aff520-d133-4124-ab92-dde7b281460a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully written to csv/ALL_CLIENTS_schedules.csv\n"
     ]
    }
   ],
   "source": [
    "# Write to CSV\n",
    "write_dicts_to_csv(schedule_list, CSV_DIR, SCHEDULES_COLLECTION_FILE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
